<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>平民</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-09-13T11:22:46.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>LXF</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Redis概述</title>
    <link href="http://yoursite.com/2017/09/13/Redis%E6%A6%82%E8%BF%B0/"/>
    <id>http://yoursite.com/2017/09/13/Redis概述/</id>
    <published>2017-09-13T04:12:08.000Z</published>
    <updated>2017-09-13T11:22:46.000Z</updated>
    
    <content type="html"><![CDATA[<p><blockquote class="blockquote-center">逃避未必能躲过，面对未必最难过</blockquote><br>在互联网时代的背景下，大数据带来的冲击，是的传统的关系型数据库结构以及数据类型无法应对，比例如大数据时代下的特点是3V(海量Volume，多样Variety，实时Velocity)，3高（高并发，高可用，高性能）。这样的特点也就是的许多菲关系型数据库NoSql（not only sql）的数据库应然而生。<br><a id="more"></a></p>
<h2 id="NoSql的概述"><a href="#NoSql的概述" class="headerlink" title="NoSql的概述"></a>NoSql的概述</h2><h3 id="NoSql简述"><a href="#NoSql简述" class="headerlink" title="NoSql简述"></a>NoSql简述</h3><p>传统的关系型数据库都是基于关系来的一对一，一对多，多对多等，这样的模型对复杂的社交网络，推荐系统中，这些场景中更注重于一种关系图谱的构建，传统的关系型数据库做这个是非常复杂和困难的。所以，一些非关系型数据库出现来解决这些问题，常用的非关系型数据库有Redis，Memcache，Mongdb。</p>
<h3 id="NoSql数据库模型简介"><a href="#NoSql数据库模型简介" class="headerlink" title="NoSql数据库模型简介"></a>NoSql数据库模型简介</h3><p>聚合模型：KV键值对,BSON，列族，图形</p>
<h3 id="在分布式数据库中CAP原理CAP-BASE"><a href="#在分布式数据库中CAP原理CAP-BASE" class="headerlink" title="在分布式数据库中CAP原理CAP+BASE"></a>在分布式数据库中CAP原理CAP+BASE</h3><h4 id="传统的ACID分别是什么"><a href="#传统的ACID分别是什么" class="headerlink" title="传统的ACID分别是什么"></a>传统的ACID分别是什么</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">A (Atomicity) 原子性</div><div class="line">C (Consistency) 一致性</div><div class="line">I (Isolation) 独立性</div><div class="line">D (Durability) 持久性</div></pre></td></tr></table></figure>
<h4 id="分布式数据库CAP"><a href="#分布式数据库CAP" class="headerlink" title="分布式数据库CAP"></a>分布式数据库CAP</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">C:Consistency（强一致性）</div><div class="line">A:Availability（可用性）</div><div class="line">P:Partition tolerance（分区容错性）</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">CA: 传统Oracle数据库 </div><div class="line">AP: 大多数网站架构的选择 </div><div class="line">CP: Redis、Mongodb</div></pre></td></tr></table></figure>
<h4 id="CAP的3进2"><a href="#CAP的3进2" class="headerlink" title="CAP的3进2"></a>CAP的3进2</h4><p>CAP理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，最多只能同时较好的满足两个。<br>因此，根据 CAP 原理将 NoSQL 数据库分成了满足 CA 原则、满足 CP 原则和满足 AP 原则三 大类：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">CA - 单点集群，满足一致性，可用性的系统，通常在可扩展性上不太强大。</div><div class="line">CP - 满足一致性，分区容忍必的系统，通常性能不是特别高。</div><div class="line">AP - 满足可用性，分区容忍性的系统，通常可能对一致性要求低一些。</div></pre></td></tr></table></figure>
<h4 id="BASE"><a href="#BASE" class="headerlink" title="BASE"></a>BASE</h4><p>BASE就是为了解决关系数据库强一致性引起的问题而引起的可用性降低而提出的解决方案。<br>BASE其实是下面三个术语的缩写：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">基本可用（Basically Available）</div><div class="line">软状态（Soft state）</div><div class="line">最终一致（Eventually consistent）</div></pre></td></tr></table></figure></p>
<p>它的思想是通过让系统放松对某一时刻数据一致性的要求来换取系统整体伸缩性和性能上改观。为什么这么说呢，缘由就在于大型系统往往由于地域分布和极高性能的要求，不可能采用分布式事务来完成这些指标，要想获得这些指标，我们必须采用另外一种方式来完成，这里BASE就是解决这个问题的办法.</p>
<h3 id="NoSql数据库四大分类"><a href="#NoSql数据库四大分类" class="headerlink" title="NoSql数据库四大分类"></a>NoSql数据库四大分类</h3><ol>
<li><p>KV键值：典型介绍</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">新浪：BerkeleyDB+redis</div><div class="line">美团：redis+tair</div><div class="line">阿里、百度：memcache+redis</div></pre></td></tr></table></figure>
</li>
<li><p>文档型数据库(bson格式比较多)：典型介绍  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">CouchDB</div><div class="line">MongoDB</div></pre></td></tr></table></figure>
</li>
<li><p>列存储数据库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Cassandra</div><div class="line">HBase</div><div class="line">分布式文件系统</div></pre></td></tr></table></figure>
</li>
<li><p>图关系数据库<br>它不是放图形的，放的是关系比如:朋友圈社交网络、广告推荐系统、社交网络，推荐系统等。专注于构建关系图谱</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Neo4J</div><div class="line">InfoGrid</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Redis入门介绍"><a href="#Redis入门介绍" class="headerlink" title="Redis入门介绍"></a>Redis入门介绍</h2><h3 id="入门概述"><a href="#入门概述" class="headerlink" title="入门概述"></a>入门概述</h3><h4 id="1-是什么"><a href="#1-是什么" class="headerlink" title="1.是什么"></a>1.是什么</h4><p>Redis:REmote DIctionary Server(远程字典服务器)是完全开源免费的，用C语言编写的，遵守BSD协议，是一个高性能的(key/value)分布式内存数据库，基于内存运行,并支持持久化的NoSQL数据库，是当前最热门的NoSql数据库之一,也被人们称为数据结构服务器。Redis 与其他 key - value 缓存产品有以下三个特点:</p>
<ol>
<li>Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。</li>
<li>Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。</li>
<li>Redis支持数据的备份，即master-slave模式的数据备份。</li>
</ol>
<h4 id="2-能干嘛"><a href="#2-能干嘛" class="headerlink" title="2.能干嘛"></a>2.能干嘛</h4><ul>
<li>内存存储和持久化：redis支持异步将内存中的数据写到硬盘上，同时不影响继续服务</li>
<li>取最新N个数据的操作，如：可以将最新的10条评论的ID放在Redis的List集合里面</li>
<li>模拟类似于HttpSession这种需要设定过期时间的功能</li>
<li>发布、订阅消息系统</li>
<li>定时器、计数器</li>
</ul>
<h4 id="3-安装"><a href="#3-安装" class="headerlink" title="3.安装"></a>3.安装</h4><p>Linux版安装<br>下载获得redis-3.0.4.tar.gz后将它放入我们的Linux目录/opt<br>/opt目录下，解压命令:tar -zxvf redis-3.0.4.tar.gz<br>解压完成后出现文件夹：redis-3.0.4<br>进入目录:cd redis-3.0.4<br>在redis-3.0.4目录下执行make命令</p>
<h4 id="4-启动"><a href="#4-启动" class="headerlink" title="4.启动"></a>4.启动</h4><p>修改redis.conf文件将里面的daemonize no 改成 yes，让服务在后台启动<br>将默认的redis.conf拷贝到自己定义好的一个路径下，比如/myconf<br>启动: redis-server /myconf/redis.conf, redis-cli<br>连通测试:/usr/local/bin目录下运行redis-server，运行拷贝出存放了自定义conf文件目录下的redis.conf文件  </p>
<h4 id="5-关闭"><a href="#5-关闭" class="headerlink" title="5.关闭"></a>5.关闭</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">单实例关闭：redis-cli shutdown</div><div class="line">多实例关闭，指定端口关闭:redis-cli -p 6379 shutdown</div></pre></td></tr></table></figure>
<h4 id="6-Redis启动后杂项基础知识讲解"><a href="#6-Redis启动后杂项基础知识讲解" class="headerlink" title="6.Redis启动后杂项基础知识讲解"></a>6.Redis启动后杂项基础知识讲解</h4><ul>
<li>单进程:单进程模型来处理客户端的请求。对读写等事件的响应,是通过对epoll函数的包装来做到的。Redis的实际处理速度完全依靠主进程的执行效率<br>,epoll是Linux内核为处理大批量文件描述符而作了改进的epoll，是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。</li>
<li>默认16个数据库，类似数组下表从零开始，初始默认使用零号库</li>
<li>select命令切换数据库</li>
<li>dbsize查看当前数据库的key的数量</li>
<li>flushdb：清空当前库</li>
<li>Flushall:通杀全部库</li>
<li>统一密码管理，16个库都是同样密码，要么都OK要么一个也连接不上</li>
<li>Redis索引都是从零开始</li>
<li>为什么默认端口是6379</li>
</ul>
<h2 id="Redis数据类型"><a href="#Redis数据类型" class="headerlink" title="Redis数据类型"></a>Redis数据类型</h2><h3 id="一、Redis的五大数据类型"><a href="#一、Redis的五大数据类型" class="headerlink" title="一、Redis的五大数据类型"></a>一、Redis的五大数据类型</h3><h4 id="1-string（字符串）"><a href="#1-string（字符串）" class="headerlink" title="1.string（字符串）"></a>1.string（字符串）</h4><ul>
<li>string是redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。</li>
<li>string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。</li>
<li>string类型是Redis最基本的数据类型，一个redis中字符串value最多可以是512M</li>
</ul>
<h4 id="2-hash（哈希，类似java里的Map）"><a href="#2-hash（哈希，类似java里的Map）" class="headerlink" title="2.hash（哈希，类似java里的Map）"></a>2.hash（哈希，类似java里的Map）</h4><ul>
<li>Redis hash 是一个键值对集合。</li>
<li>Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。</li>
<li>类似Java里面的Map<string,object></string,object></li>
</ul>
<h4 id="3-list（列表）"><a href="#3-list（列表）" class="headerlink" title="3.list（列表）"></a>3.list（列表）</h4><ul>
<li>Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。</li>
<li>底层实际是个链表</li>
</ul>
<h4 id="4-set（集合）"><a href="#4-set（集合）" class="headerlink" title="4.set（集合）"></a>4.set（集合）</h4><ul>
<li>Redis的Set是string类型的无序集合。它是通过HashTable实现实现的，</li>
</ul>
<h4 id="5-zset-sorted-set：有序集合"><a href="#5-zset-sorted-set：有序集合" class="headerlink" title="5.zset(sorted set：有序集合)"></a>5.zset(sorted set：有序集合)</h4><ul>
<li>Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。</li>
<li>redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。</li>
</ul>
<h3 id="二、常用命令（官网常用命令"><a href="#二、常用命令（官网常用命令" class="headerlink" title="二、常用命令（官网常用命令)"></a>二、常用命令（<a href="http://redisdoc.com/" target="_blank" rel="external">官网常用命令</a>)</h3><h4 id="键（keys）"><a href="#键（keys）" class="headerlink" title="键（keys）"></a>键（keys）</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#获取当前库的全部键</span></div><div class="line">keys *</div><div class="line"><span class="comment">#判断某个key是否存在</span></div><div class="line">exists key</div><div class="line"><span class="comment">#当前库就没有了，被移除了</span></div><div class="line">move key db</div><div class="line"><span class="comment">#为给定的key设置过期时间</span></div><div class="line">expire key 秒钟</div><div class="line"><span class="comment">#查看还有多少秒过期，-1表示永不过期，-2表示已过期</span></div><div class="line">ttl key </div><div class="line"><span class="comment">#查看你的key是什么类型</span></div><div class="line"><span class="built_in">type</span> key</div></pre></td></tr></table></figure>
<h4 id="字符串（String）"><a href="#字符串（String）" class="headerlink" title="字符串（String）"></a>字符串（String）</h4><p>它是单值单value的<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">set</span>/get/del/append/strlen</div><div class="line">Incr/decr/incrby/decrby,一定要是数字才能进行加减</div><div class="line">getrange:获取指定区间范围内的值，类似between......and的关系，从零到负一表示全部</div><div class="line">setrange:setrange设置指定区间范围内的值，格式是setrange key值 具体值</div><div class="line">setex(<span class="built_in">set</span> with expire)键秒值/setnx(<span class="built_in">set</span> <span class="keyword">if</span> not exist)</div><div class="line">mset:同时设置一个或多个 key-value 对</div><div class="line">mget:获取所有(一个或多个)给定 key 的值</div><div class="line">msetnx:同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在</div><div class="line">getset(先get再<span class="built_in">set</span>)</div></pre></td></tr></table></figure></p>
<h4 id="Redis列表-List"><a href="#Redis列表-List" class="headerlink" title="Redis列表(List)"></a>Redis列表(List)</h4><p>它是单值多value<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">lpush/rpush/lrange</div><div class="line">lpop/rpop</div><div class="line">lindex，按照索引下标获得元素(从上到下)</div><div class="line">llen</div><div class="line">lrem key 删N个value</div><div class="line">ltrim key 开始index 结束index，截取指定范围的值后再赋值给key</div><div class="line">rpoplpush 源列表 目的列表</div><div class="line">lset key index value</div><div class="line">linsert key  before/after 值1 值2</div></pre></td></tr></table></figure></p>
<p>性能总结:它是一个字符串链表，left、right都可以插入添加；如果键不存在，创建新的链表；如果键已存在，新增内容；如果值全移除，对应的键也就消失了。链表的操作无论是头和尾效率都极高，但假如是对中间元素进行操作，效率就很惨淡了。</p>
<h4 id="Redis集合-Set"><a href="#Redis集合-Set" class="headerlink" title="Redis集合(Set)"></a>Redis集合(Set)</h4><p>它是单值多value</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">sadd/smembers/sismember</div><div class="line"><span class="comment">#获取集合里面的元素个数</span></div><div class="line">scard</div><div class="line"><span class="comment">#删除集合中元素</span></div><div class="line">srem key value </div><div class="line"><span class="comment">#如果超过最大数量就全部取出，如果写的值是负数，比如-3 ，表示需要取出3个，但是可能会有重复值。</span></div><div class="line">srandmember key 某个整数(随机出几个数)</div><div class="line"><span class="comment">#随机出栈</span></div><div class="line">spop key</div><div class="line"><span class="comment">#作用是将key1里的某个值赋给key2</span></div><div class="line">smove key1 key2 在key1里某个值</div><div class="line"><span class="comment">#在第一个set里面而不在后面任何一个set里面的项</span></div><div class="line">差集：sdiff</div><div class="line"><span class="comment">#在第一个set里面并且在后面任何一个set里面的项</span></div><div class="line">交集：sinter</div><div class="line"><span class="comment">#在第一个set里面或者在后面任何一个set里面的项</span></div><div class="line">并集：sunion</div></pre></td></tr></table></figure>
<h4 id="Redis哈希-Hash"><a href="#Redis哈希-Hash" class="headerlink" title="Redis哈希(Hash)"></a>Redis哈希(Hash)</h4><p>KV模式不变，但V是一个键值对</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">hset/hget/hmset/hmget/hgetall/hdel</div><div class="line">hlen</div><div class="line">hexists key 在key里面的某个值的key</div><div class="line">hkeys/hvals</div><div class="line">hincrby/hincrbyfloat</div><div class="line">hsetnx</div></pre></td></tr></table></figure>
<h4 id="Redis有序集合Zset-sorted-set"><a href="#Redis有序集合Zset-sorted-set" class="headerlink" title="Redis有序集合Zset(sorted set)"></a>Redis有序集合Zset(sorted set)</h4><p>在set基础上，加一个score值。<br>之前set是k1 v1 v2 v3，现在zset是k1 score1 v1 score2 v2</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">zadd/zrange </div><div class="line">zrem key 某score下对应的value值，作用是删除元素</div><div class="line"><span class="comment">#获取集合中元素个数</span></div><div class="line">zcard</div><div class="line"><span class="comment">#获取分数区间内元素个数</span></div><div class="line">zcount</div><div class="line">zcount key 开始分数区间 结束分数区间</div><div class="line"><span class="comment">#获取value在zset中的下标位置</span></div><div class="line">zrank</div><div class="line"><span class="comment">#按照值获得对应的分数</span></div><div class="line">zscore</div><div class="line"><span class="comment">#作用是逆序获得下标值</span></div><div class="line">zrevrank key values值，</div><div class="line">zrevrange</div><div class="line">zrevrangebyscore  key 结束score 开始score</div></pre></td></tr></table></figure>
<h2 id="解析配置文件"><a href="#解析配置文件" class="headerlink" title="解析配置文件"></a>解析配置文件</h2><h3 id="redis-conf"><a href="#redis-conf" class="headerlink" title="redis.conf"></a>redis.conf</h3><ol>
<li><p>GENERAL通用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">daemonize:默认为no，改为yes</div><div class="line">pidfile</div><div class="line">port</div><div class="line">tcp-backlog:设置tcp的backlog，backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。注意Linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值，所以需要确认增大somaxconn和tcp_max_syn_backlog两个值来达到想要的效果</div><div class="line">timeout</div><div class="line">bind </div><div class="line">tcp-keepalive:单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置成60 </div><div class="line">loglevel:日志级别</div><div class="line">logfile：日志文件名</div><div class="line">syslog-enabled：是否把日志输出到syslog中</div><div class="line">syslog-ident：指定syslog里的日志标志</div><div class="line">syslog-facility：指定syslog设备，值可以是USER或LOCAL0-LOCAL7</div><div class="line">databases</div></pre></td></tr></table></figure>
</li>
<li><p>SNAPSHOTTING快照</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Save</div><div class="line">	save 秒钟 写操作次数</div><div class="line">	禁用</div><div class="line">stop-writes-on-bgsave-error</div><div class="line">rdbcompression</div><div class="line">rdbchecksum</div><div class="line">dbfilename</div><div class="line">dir</div></pre></td></tr></table></figure>
</li>
<li><p>REPLICATION复制</p>
</li>
<li>SECURITY安全<br>访问密码的查看、设置和取消</li>
<li><p>LIMITS限制</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#最大客户端个数</span></div><div class="line">maxclients</div><div class="line"><span class="comment">#允许最大使用内存</span></div><div class="line">maxmemory</div><div class="line"><span class="comment">#内存过期清除策略</span></div><div class="line">maxmemory-policy</div><div class="line">  <span class="comment">#使用LRU算法移除key，只对设置了过期时间的键</span></div><div class="line">  (1)volatile-lru</div><div class="line">  <span class="comment">#使用LRU算法移除key</span></div><div class="line">  (2)allkeys-lru</div><div class="line">  <span class="comment">#在过期集合中移除随机的key，只对设置了过期时间的键</span></div><div class="line">  (3)volatile-random</div><div class="line">  <span class="comment">#移除随机的key</span></div><div class="line">  (4)allkeys-random</div><div class="line">  <span class="comment">#移除那些TTL值最小的key，即那些最近要过期的key</span></div><div class="line">  (5)volatile-ttl</div><div class="line">  <span class="comment">#不进行移除。针对写操作，只是返回错误信息</span></div><div class="line">  (6)noeviction</div><div class="line"><span class="comment">#设置样本数量，LRU算法和最小TTL算法都并非是精确的算法，而是估算值，所以</span></div><div class="line"><span class="comment">#你可以设置样本的大小，redis默认会检查这么多个key并选择其中LRU的那个。</span></div><div class="line">maxmemory-samples</div></pre></td></tr></table></figure>
</li>
<li><p>APPEND ONLY MODE追加</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#是否打开</span></div><div class="line">appendonly</div><div class="line"><span class="comment">#文件名称</span></div><div class="line">appendfilename</div><div class="line"><span class="comment">#追加策略</span></div><div class="line">appendfsync</div><div class="line">  <span class="comment">#同步持久化 每次发生数据变更会被立即记录到磁盘  性能较差但数据完整性比较好</span></div><div class="line">  (1)always</div><div class="line">  <span class="comment">#出厂默认推荐，异步操作，每秒记录   如果一秒内宕机，有数据丢失</span></div><div class="line">  (2)everysec</div><div class="line">  <span class="comment">#不追加，不推荐</span></div><div class="line">  (3)no</div><div class="line"><span class="comment">#重写时是否可以运用Appendfsync，用默认no即可，保证数据安全性。</span></div><div class="line">no-appendfsync-on-rewrite</div><div class="line">  <span class="comment">#设置重写的基准值</span></div><div class="line">  (1)auto-aof-rewrite-min-size</div><div class="line">  <span class="comment">#设置重写的基准值</span></div><div class="line">  (2)auto-aof-rewrite-percentage</div></pre></td></tr></table></figure>
</li>
<li><p>常见配置<code>redis.conf</code>介绍总结</p>
<ol>
<li><p>Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用<code>yes</code>启用守护进程</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">daemonize no</div></pre></td></tr></table></figure>
</li>
<li><p>当Redis以守护进程方式运行时，Redis默认会把pid写入<code>/var/run/redis.pid</code>文件，可以通过pidfile指定。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pidfile /var/run/redis.pid</div></pre></td></tr></table></figure>
</li>
<li><p>指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">port 6379</div></pre></td></tr></table></figure>
</li>
<li><p>绑定的主机地址。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">bind</span> 127.0.0.1</div></pre></td></tr></table></figure>
</li>
<li><p>当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">timeout 300</div></pre></td></tr></table></figure>
</li>
<li><p>指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">loglevel verbose</div></pre></td></tr></table></figure>
</li>
<li><p>日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给<code>/dev/null</code>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">logfile stdout</div></pre></td></tr></table></figure>
</li>
<li><p>设置数据库的数量，默认数据库为0，可以使用<code>SELECT &lt;dbid&gt;</code>命令在连接上指定数据库id。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">databases 16</div></pre></td></tr></table></figure>
</li>
<li><p>指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">save &lt;seconds&gt; &lt;changes&gt;</div></pre></td></tr></table></figure>
<p>Redis默认配置文件中提供了三个条件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#900秒（15分钟）内有1个更改</span></div><div class="line">save 900 1</div><div class="line"><span class="comment">#300秒（5分钟)内有10个更改</span></div><div class="line">save 300 10</div><div class="line"><span class="comment">#60秒内有10000个更改</span></div><div class="line">save 60 10000</div></pre></td></tr></table></figure>
</li>
<li><p>指定存储至本地数据库时是否压缩数据，默认为<code>yes</code>，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rdbcompression yes</div></pre></td></tr></table></figure>
</li>
<li><p>指定本地数据库文件名，默认值为<code>dump.rdb</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dbfilename dump.rdb</div></pre></td></tr></table></figure>
</li>
<li><p>指定本地数据库存放目录。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dir ./</div></pre></td></tr></table></figure>
</li>
<li><p>设置当本机为slave服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">slaveof &lt;masterip&gt; &lt;masterport&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>当master服务设置了密码保护时，slave服务连接master的密码。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">masterauth &lt;master-password&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过<code>AUTH &lt;password&gt;</code>命令提供密码，默认关闭。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">requirepass foobared</div></pre></td></tr></table></figure>
</li>
<li><p>设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置<code>maxclients 0</code>，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">maxclients 128</div></pre></td></tr></table></figure>
</li>
<li><p>指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">maxmemory &lt;bytes&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为<code>no</code>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">appendonly no</div></pre></td></tr></table></figure>
</li>
<li><p>指定更新日志文件名，默认为appendonly.aof</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">appendfilename appendonly.aof</div></pre></td></tr></table></figure>
</li>
<li><p>指定更新日志条件，共有3个可选值： </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">appendfsync everysec</div><div class="line">no：表示等操作系统进行数据缓存同步到磁盘（快） </div><div class="line">always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） </div><div class="line">everysec：表示每秒同步一次（折衷，默认值）</div></pre></td></tr></table></figure>
</li>
<li><p>指定是否启用虚拟内存机制，默认值为<code>no</code>，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制）。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vm-enabled no</div></pre></td></tr></table></figure>
</li>
<li><p>虚拟内存文件路径，默认值为<code>/tmp/redis.swap</code>，不可多个Redis实例共享。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vm-swap-file /tmp/redis.swap</div></pre></td></tr></table></figure>
</li>
<li><p>将所有大于<code>vm-max-memory</code>的数据存入虚拟内存,无论<code>vm-max-memory</code>设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当<code>vm-max-memory</code>设置为0的时候,其实是所有value都存在于磁盘。默认值为0。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vm-max-memory 0</div></pre></td></tr></table></figure>
</li>
<li><p>Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，<code>vm-page-size</code>是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vm-page-size 32</div></pre></td></tr></table></figure>
</li>
<li><p>设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vm-pages 134217728</div></pre></td></tr></table></figure>
</li>
<li><p>设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vm-max-threads 4</div></pre></td></tr></table></figure>
</li>
<li><p>设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">glueoutputbuf yes</div></pre></td></tr></table></figure>
</li>
<li><p>指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">hash</span>-max-zipmap-entries 64</div><div class="line"><span class="built_in">hash</span>-max-zipmap-value 512</div></pre></td></tr></table></figure>
</li>
<li><p>指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍）。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">activerehashing yes</div></pre></td></tr></table></figure>
</li>
<li><p>指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">include /path/to/local.conf</div></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ol>
<h2 id="redis的持久化"><a href="#redis的持久化" class="headerlink" title="redis的持久化"></a>redis的持久化</h2><h3 id="RDB（Redis-DataBase）"><a href="#RDB（Redis-DataBase）" class="headerlink" title="RDB（Redis DataBase）"></a>RDB（Redis DataBase）</h3><p>在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里。它可以手动执行，也可以再<code>redis.conf</code>中配置，定期执行。Redis会单独创（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。rdb保存的默认是<code>dump.rdb</code>文件，它是经过压缩的二进制文件。  </p>
<p>RDB的缺点是最后一次持久化后的数据可能丢失。</p>
<ul>
<li><p>自动保存间隔<br>BGSAVE可以在不阻塞主进程的情况下完成数据的备份。可以通过<code>redis.conf</code>中设置多个自动保存条件，只要有一个条件被满足，服务器就会执行<code>BGSAVE</code>命令。</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 以下配置表示的条件：</span></div><div class="line"><span class="comment"># 服务器在900秒之内被修改了1次</span></div><div class="line">save 900 1</div><div class="line"><span class="comment"># 服务器在300秒之内被修改了10次</span></div><div class="line">save 300 10</div><div class="line"><span class="comment"># 服务器在60秒之内被修改了10000次</span></div><div class="line">save 60 10000</div><div class="line"><span class="comment">#表示不同步</span></div><div class="line">save “”</div></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>如何触发（创建）RDB快照<br>冷拷贝后重新使用<br>  可以<code>cp dump.rdb dump_new.rdb</code><br>RDB文件可以通过两个命令来生成：命令<code>save</code>或者是<code>bgsave</code><br>  <code>Save</code>：save时只管保存，其它不管，全部阻塞。<br>  <code>BGSAVE</code>：Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。即派生(fork)一个子进程来创建新的RDB文件，记录接收到BGSAVE当时的数据库状态，父进程继续处理接收到的命令，子进程完成文件的创建之后，会发送信号给父进程，而与此同时，父进程处理命令的同时，通过轮询来接收子进程的信号。可以通过<code>lastsave</code>命令获取最后一次成功执行快照的时间，执行<code>flushall</code>命令，也会产生<code>dump.rdb</code>文件，但里面是空的，无意义。</li>
</ul>
<ul>
<li><p>如何恢复<br>而RDB文件的载入一般情况是自动的，redis服务器启动的时候，redis服务器再启动的时候如果检测到RDB文件的存在，那么redis会自动载入这个文件。</p>
</li>
<li><p>如何停止<br>动态所有停止RDB保存规则的方法：<code>redis-cli config set save &quot;&quot;</code></p>
</li>
<li><p>优劣势<br>  适合大规模的数据恢复<br>  对数据完整性和一致性要求不高<br>  在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改<br>fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑</p>
</li>
</ul>
<h3 id="AOF（Append-Only-File）"><a href="#AOF（Append-Only-File）" class="headerlink" title="AOF（Append Only File）"></a>AOF（Append Only File）</h3><p>以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作Aof保存的是appendonly.aof文件。</p>
<ul>
<li><p>AOF启动/修复/恢复<br>  正常恢复</p>
<pre><code>启动：设置`Yes`，修改默认的`appendonly no`，改为`yes`
将有数据的aof文件复制一份保存到对应目录(config get dir)
恢复：重启redis然后重新加载
</code></pre><p>  异常恢复</p>
<pre><code>启动：设置`Yes`，修改默认的`appendonly no`，改为`yes`
备份被写坏的AOF文件
修复：`redis-check-aof --fix`进行修复
恢复：重启redis然后重新加载
</code></pre></li>
<li><p>rewrite<br>AOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制,当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集，可以使用命令<code>bgrewriteaof</code><br>重写原理<br>AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)，遍历新进程的内存中数据，每条记录有一条的Set语句。重写aof文件的操作，<br>并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。</p>
</li>
<li><p>触发机制<br>  Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发<br>优势<br>每修改同步：appendfsync always   同步持久化 每次发生数据变更会被立即记录到磁盘  性能较差但数据完整性比较好<br>每秒同步：appendfsync everysec<br>异步操作，每秒记录   如果一秒内宕机，有数据丢失<br>不同步：appendfsync no   从不同步<br>劣势<br>相同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢于rdb。<br>aof运行效率要慢于rdb,每秒同步策略效率较好，不同步效率和rdb相同。</p>
</li>
<li><p>官网建议  </p>
<pre><code>RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储
AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些
</code></pre><p>命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.<br>Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大</p>
<pre><code>只做缓存：如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式.
同时开启两种持久化方式
    在这种情况下,当redis重启的时候会优先载入AOF文件来恢复原始的数据,
</code></pre><p>因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整.</p>
<pre><code>RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。那要不要只使用AOF呢？
</code></pre><p>作者建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份)，<br>快速重启，而且不会有AOF可能潜在的bug，留着作为一个万一的手段。</p>
</li>
<li><p>性能建议<br>因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留<code>save 900 1</code>这条规则。<br>如果Enalbe AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。代价一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。<br>如果不Enable AOF ，仅靠Master-Slave Replication 实现高可用性也可以。能省掉一大笔IO也减少了rewrite时带来的系统波动。代价是如果Master/Slave同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个。新浪微博就选用了这种架构。</p>
</li>
</ul>
<h2 id="Redis的事务"><a href="#Redis的事务" class="headerlink" title="Redis的事务"></a>Redis的事务</h2><p>可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按顺序地串行化执行而不会被其它命令插入，不许加塞，一个队列中，一次性、顺序性、排他性的执行一系列命令。</p>
<ul>
<li>常见案例<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div></pre></td><td class="code"><pre><div class="line">Case1：正常执行</div><div class="line">Case2：放弃事务--&gt;中途放弃事物</div><div class="line">Case3：全体连坐--&gt;如果中间有“错误”则全部放弃执行</div><div class="line">Case4：冤头债主--&gt;执行过程中遇到某个不可执行的操作，则其他可以执行的放行。</div><div class="line">Case5：watch监控</div><div class="line">```	</div><div class="line"></div><div class="line">* 悲观锁/乐观锁/CAS(Check And Set)</div><div class="line">悲观锁：提交版本必须大于记录当前版本才能执行更新，传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。  </div><div class="line">乐观锁：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量。</div><div class="line">初始化信用卡可用余额和欠额</div><div class="line">无加塞篡改，先监控再开启multi，</div><div class="line">保证两笔金额变动在同一个事务内</div><div class="line">有加塞篡改</div><div class="line">监控了key，如果key被修改了，后面一个事务的执行失效</div><div class="line">unwatch</div><div class="line">一旦执行了<span class="built_in">exec</span>之前加的监控锁都会被取消掉了</div><div class="line">CAS</div><div class="line"></div><div class="line">* 小结 </div><div class="line">Watch指令，类似乐观锁，事务提交时，如果Key的值已被别的客户端改变，比如某个list已被别的客户端push/pop过了，整个事务队列都不会被执行通过WATCH命令在事务执行之前监控了多个Keys，倘若在WATCH之后有任何Key的值发生了变化，EXEC命令执行的事务都将被放弃，同时返回Nullmulti-bulk应答以通知调用者事务执行失败。</div><div class="line">* 3阶段</div><div class="line">开启：以MULTI开始一个事务</div><div class="line">入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面</div><div class="line">执行：由EXEC命令触发事务</div><div class="line">* 3特性</div><div class="line">单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</div><div class="line">没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题。</div><div class="line">不保证原子性：redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚。</div><div class="line"></div><div class="line"><span class="comment">## Redis的发布订阅</span></div><div class="line">进程间的一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。</div><div class="line">命令 </div><div class="line">先订阅后发布后才能收到消息  </div><div class="line"></div><div class="line">1. 可以一次性订阅多个，SUBSCRIBE c1 c2 c3</div><div class="line">2. 消息发布，PUBLISH c2 hello-redis</div><div class="line">3. 订阅多个，通配符\*， PSUBSCRIBE new \*</div><div class="line">4. 收取消息， PUBLISH new1 redis2015</div><div class="line"></div><div class="line"><span class="comment">## Redis的复制(Master/Slave)</span></div><div class="line">也就是我们所说的主从复制，主机数据更新后根据配置和策略，</div><div class="line">自动同步到备机的master/slaver机制，Master以写为主，Slave以读为主</div><div class="line">做什么：</div><div class="line">		读写分离</div><div class="line">		容灾恢复</div><div class="line">怎么玩：</div><div class="line">配从(库)不配主(库)</div><div class="line">从库配置：slaveof 主库IP 主库端口</div><div class="line">	每次与master断开之后，都需要重新连接，除非你配置进redis.conf文件</div><div class="line">	info replication</div><div class="line">修改配置文件细节操作</div><div class="line">	拷贝多个redis.conf文件</div><div class="line">	开启daemonize yes</div><div class="line">	pid文件名字</div><div class="line">	指定端口</div><div class="line">	<span class="built_in">log</span>文件名字</div><div class="line">	dump.rdb名字</div><div class="line">常用3招</div><div class="line">一主二仆</div><div class="line">	Init</div><div class="line">	一个Master两个Slave</div><div class="line">	日志查看</div><div class="line">		主机日志</div><div class="line">		备机日志</div><div class="line">		 info replication</div><div class="line">	主从问题演示</div><div class="line">薪火相传</div><div class="line">上一个Slave可以是下一个slave的Master，Slave同样可以接收其他</div><div class="line">slaves的连接和同步请求，那么该slave作为了链条中下一个的master,</div><div class="line">可以有效减轻master的写压力</div><div class="line">中途变更转向:会清除之前的数据，重新建立拷贝最新的</div><div class="line">slaveof 新主库IP 新主库端口</div><div class="line">反客为主</div><div class="line">SLAVEOF no one</div><div class="line">使当前数据库停止与其他数据库的同步，转成主数据库</div><div class="line">复制原理</div><div class="line">slave启动成功连接到master后会发送一个sync命令</div><div class="line">Master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，</div><div class="line">在后台进程执行完毕之后，master将传送整个数据文件到slave,以完成一次完全同步</div><div class="line">全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。</div><div class="line">增量复制：Master继续将新的所有收集到的修改命令依次传给slave,完成同步</div><div class="line">但是只要是重新连接master,一次完全同步（全量复制)将被自动执行</div><div class="line">哨兵模式(sentinel)</div><div class="line">是什么</div><div class="line">反客为主的自动版，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库</div><div class="line">怎么玩(使用步骤)</div><div class="line">调整结构，6379带着80、81</div><div class="line">自定义的/myredis目录下新建sentinel.conf文件，名字绝不能错</div><div class="line">配置哨兵,填写内容</div><div class="line"> sentinel monitor 被监控数据库名字(自己起名字) 127.0.0.1 6379 1</div><div class="line">上面最后一个数字1，表示主机挂掉后salve投票看让谁接替成为主机，得票数多少后成为主机</div><div class="line">启动哨兵</div><div class="line">redis-sentinel /myredis/sentinel.conf </div><div class="line">上述目录依照各自的实际情况配置，可能目录不同</div><div class="line">正常主从演示</div><div class="line">原有的master挂了</div><div class="line">投票新选</div><div class="line">重新主从继续开工,info replication查查看</div><div class="line">问题：如果之前的master重启回来，会不会双master冲突？</div><div class="line">一组sentinel能同时监控多个Master</div><div class="line">子主题 7</div><div class="line">复制的缺点</div><div class="line">复制延时：由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。</div><div class="line">Redis的Java客户端Jedis</div><div class="line">安装JDK</div><div class="line">tar -zxvf jdk-7u67-linux-i586.tar.gz</div><div class="line">vi /etc/profile</div><div class="line">重启一次Centos</div><div class="line">编码验证</div><div class="line">安装eclipse</div><div class="line">Jedis所需要的jar包</div><div class="line">commons-pool-1.6.jar</div><div class="line">jedis-2.1.0.jar</div><div class="line">Jedis常用操作</div><div class="line">测试连通性</div><div class="line">5+1</div><div class="line">一个key</div><div class="line">五大数据类型</div><div class="line">事务提交</div><div class="line">日常：</div><div class="line">			</div><div class="line">```java</div><div class="line">package com.atguigu.redis.test;</div><div class="line">import redis.clients.jedis.Jedis;</div><div class="line">import redis.clients.jedis.Response;</div><div class="line">import redis.clients.jedis.Transaction;</div><div class="line">public class Test03 </div><div class="line">&#123;</div><div class="line">  public static void main(String[] args) </div><div class="line">  &#123;</div><div class="line">     Jedis jedis = new Jedis(<span class="string">"127.0.0.1"</span>,6379);</div><div class="line">     </div><div class="line">     //监控key，如果该动了事务就被放弃</div><div class="line">     /*3</div><div class="line">     jedis.watch(<span class="string">"serialNum"</span>);</div><div class="line">     jedis.set(<span class="string">"serialNum"</span>,<span class="string">"s#####################"</span>);</div><div class="line">     jedis.unwatch();*/</div><div class="line">     </div><div class="line">     Transaction transaction = jedis.multi();//被当作一个命令进行执行</div><div class="line">     Response&lt;String&gt; response = transaction.get(<span class="string">"serialNum"</span>);</div><div class="line">     transaction.set(<span class="string">"serialNum"</span>,<span class="string">"s002"</span>);</div><div class="line">     response = transaction.get(<span class="string">"serialNum"</span>);</div><div class="line">     transaction.lpush(<span class="string">"list3"</span>,<span class="string">"a"</span>);</div><div class="line">     transaction.lpush(<span class="string">"list3"</span>,<span class="string">"b"</span>);</div><div class="line">     transaction.lpush(<span class="string">"list3"</span>,<span class="string">"c"</span>);</div><div class="line">     </div><div class="line">     transaction.exec();</div><div class="line">     //2 transaction.discard();</div><div class="line">     System.out.println(<span class="string">"serialNum***********"</span>+response.get());</div><div class="line">          </div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>加锁</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestTransaction</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">transMethod</span><span class="params">()</span> </span>&#123;</div><div class="line">     Jedis jedis = <span class="keyword">new</span> Jedis(<span class="string">"127.0.0.1"</span>, <span class="number">6379</span>);</div><div class="line">     <span class="keyword">int</span> balance;<span class="comment">// 可用余额</span></div><div class="line">     <span class="keyword">int</span> debt;<span class="comment">// 欠额</span></div><div class="line">     <span class="keyword">int</span> amtToSubtract = <span class="number">10</span>;<span class="comment">// 实刷额度</span></div><div class="line">     jedis.watch(<span class="string">"balance"</span>);</div><div class="line">     <span class="comment">//jedis.set("balance","5");//此句不该出现，讲课方便。模拟其他程序已经修改了该条目</span></div><div class="line">     balance = Integer.parseInt(jedis.get(<span class="string">"balance"</span>));</div><div class="line">     <span class="keyword">if</span> (balance &lt; amtToSubtract) &#123;</div><div class="line">       jedis.unwatch();</div><div class="line">       System.out.println(<span class="string">"modify"</span>);</div><div class="line">       <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">     &#125; <span class="keyword">else</span> &#123;</div><div class="line">       System.out.println(<span class="string">"***********transaction"</span>);</div><div class="line">       Transaction transaction = jedis.multi();</div><div class="line">       transaction.decrBy(<span class="string">"balance"</span>, amtToSubtract);</div><div class="line">       transaction.incrBy(<span class="string">"debt"</span>, amtToSubtract);</div><div class="line">       transaction.exec();</div><div class="line">       balance = Integer.parseInt(jedis.get(<span class="string">"balance"</span>));</div><div class="line">       debt = Integer.parseInt(jedis.get(<span class="string">"debt"</span>));</div><div class="line">       System.out.println(<span class="string">"*******"</span> + balance);</div><div class="line">       System.out.println(<span class="string">"*******"</span> + debt);</div><div class="line">       <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">     &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">/**</span></div><div class="line">   * 通俗点讲，watch命令就是标记一个键，如果标记了一个键， 在提交事务前如果该键被别人修改过，那事务就会失败，这种情况通常可以在程序中</div><div class="line">   * 重新再尝试一次。</div><div class="line">   * 首先标记了键balance，然后检查余额是否足够，不足就取消标记，并不做扣减； 足够的话，就启动事务进行更新操作，</div><div class="line">   * 如果在此期间键balance被其它人修改， 那在提交事务（执行exec）时就会报错， 程序中通常可以捕获这类错误再重新执行一次，直到成功。</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">     TestTransaction test = <span class="keyword">new</span> TestTransaction();</div><div class="line">     <span class="keyword">boolean</span> retValue = test.transMethod();</div><div class="line">     System.out.println(<span class="string">"main retValue-------: "</span> + retValue);</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>主从复制<br>            6379,6380启动，先各自先独立<br>            主写<br>            从读</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</div><div class="line">     Jedis jedis_M = <span class="keyword">new</span> Jedis(<span class="string">"127.0.0.1"</span>,<span class="number">6379</span>);</div><div class="line">     Jedis jedis_S = <span class="keyword">new</span> Jedis(<span class="string">"127.0.0.1"</span>,<span class="number">6380</span>);</div><div class="line">     </div><div class="line">     jedis_S.slaveof(<span class="string">"127.0.0.1"</span>,<span class="number">6379</span>);</div><div class="line">     jedis_M.set(<span class="string">"k6"</span>,<span class="string">"v6"</span>);</div><div class="line">     Thread.sleep(<span class="number">500</span>);</div><div class="line">     System.out.println(jedis_S.get(<span class="string">"k6"</span>));</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>JedisPool<br>        获取Jedis实例需要从JedisPool中获取<br>        用完Jedis实例需要返还给JedisPool<br>        如果Jedis在使用过程中出错，则也需要还给JedisPool<br>        案例见代码: JedisPoolUtil</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">			</div><div class="line"><span class="keyword">package</span> com.atguigu.redis.test;</div><div class="line"></div><div class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</div><div class="line"><span class="keyword">import</span> redis.clients.jedis.JedisPool;</div><div class="line"><span class="keyword">import</span> redis.clients.jedis.JedisPoolConfig;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JedisPoolUtil</span> </span>&#123;</div><div class="line"></div><div class="line"><span class="comment">//被volatile修饰的变量不会被本地线程缓存，对该变量的读写都是直接操作共享内存。</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> JedisPool jedisPool = <span class="keyword">null</span>;</div><div class="line">             </div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="title">JedisPoolUtil</span><span class="params">()</span> </span>&#123;&#125;</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> JedisPool <span class="title">getJedisPoolInstance</span><span class="params">()</span></span>&#123;</div><div class="line">  </div><div class="line">     <span class="keyword">if</span>(<span class="keyword">null</span> == jedisPool)&#123;</div><div class="line">     </div><div class="line">       <span class="keyword">synchronized</span> (JedisPoolUtil.class)&#123;</div><div class="line">       </div><div class="line">          <span class="keyword">if</span>(<span class="keyword">null</span> == jedisPool)&#123;</div><div class="line">          	JedisPoolConfig poolConfig = <span class="keyword">new</span> JedisPoolConfig();</div><div class="line">           	poolConfig.setMaxActive(<span class="number">1000</span>);</div><div class="line">           	poolConfig.setMaxIdle(<span class="number">32</span>);</div><div class="line">           	poolConfig.setMaxWait(<span class="number">100</span>*<span class="number">1000</span>);</div><div class="line">           	poolConfig.setTestOnBorrow(<span class="keyword">true</span>);</div><div class="line">            </div><div class="line">          	jedisPool = <span class="keyword">new</span> JedisPool(poolConfig,<span class="string">"127.0.0.1"</span>);</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">     <span class="keyword">return</span> jedisPool;</div><div class="line"> &#125;</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">release</span><span class="params">(JedisPool jedisPool,Jedis jedis)</span></span>&#123;</div><div class="line">     <span class="keyword">if</span>(<span class="keyword">null</span> != jedis)&#123;</div><div class="line">      jedisPool.returnResourceObject(jedis);</div><div class="line">     &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>jedisPool.getResource();</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.atguigu.redis.test;  </div><div class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</div><div class="line"><span class="keyword">import</span> redis.clients.jedis.JedisPool;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test01</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">     JedisPool jedisPool = JedisPoolUtil.getJedisPoolInstance();</div><div class="line">     Jedis jedis = <span class="keyword">null</span>;</div><div class="line">     </div><div class="line">     <span class="keyword">try</span> </div><div class="line">     &#123;</div><div class="line">       jedis = jedisPool.getResource();</div><div class="line">       jedis.set(<span class="string">"k18"</span>,<span class="string">"v183"</span>);</div><div class="line">       </div><div class="line">     &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">       	e.printStackTrace();</div><div class="line">     &#125;<span class="keyword">finally</span>&#123;</div><div class="line">       	JedisPoolUtil.release(jedisPool, jedis);</div><div class="line">     &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>JedisPoolConfig配置总结<br>JedisPool的配置参数大部分是由JedisPoolConfig的对应项来赋值的。</p>
<p>maxActive：控制一个pool可分配多少个jedis实例，通过pool.getResource()来获取；如果赋值为-1，则表示不限制；如果pool已经分配了maxActive个jedis实例，则此时pool的状态为exhausted。<br>maxIdle：控制一个pool最多有多少个状态为idle(空闲)的jedis实例；<br>whenExhaustedAction：表示当pool中的jedis实例都被allocated完时，pool要采取的操作；默认有三种。<br> WHEN_EXHAUSTED_FAIL –&gt; 表示无jedis实例时，直接抛出NoSuchElementException；<br> WHEN_EXHAUSTED_BLOCK –&gt; 则表示阻塞住，或者达到maxWait时抛出JedisConnectionException；<br> WHEN_EXHAUSTED_GROW –&gt; 则表示新建一个jedis实例，也就说设置的maxActive无用；<br>maxWait：表示当borrow一个jedis实例时，最大的等待时间，如果超过等待时间，则直接抛JedisConnectionException；<br>testOnBorrow：获得一个jedis实例的时候是否检查连接可用性（ping()）；如果为true，则得到的jedis实例均是可用的；<br>testOnReturn：return 一个jedis实例给pool时，是否检查连接可用性（ping()）；<br>testWhileIdle：如果为true，表示有一个idle object evitor线程对idle object进行扫描，如果validate失败，此object会被从pool中drop掉；这一项只有在timeBetweenEvictionRunsMillis大于0时才有意义；<br>timeBetweenEvictionRunsMillis：表示idle object evitor两次扫描之间要sleep的毫秒数；<br>numTestsPerEvictionRun：表示idle object evitor每次扫描的最多的对象数；<br>minEvictableIdleTimeMillis：表示一个对象至少停留在idle状态的最短时间，然后才能被idle object evitor扫描并驱逐；这一项只有在timeBetweenEvictionRunsMillis大于0时才有意义；<br>softMinEvictableIdleTimeMillis：在minEvictableIdleTimeMillis基础上，加入了至少minIdle个对象已经在pool里面了。如果为-1，evicted不会根据idle time驱逐任何对象。如果minEvictableIdleTimeMillis&gt;0，则此项设置无意义，且只有在timeBetweenEvictionRunsMillis大于0时才有意义；</p>
<h1 id="lifo：borrowObject返回对象时，是采用DEFAULT-LIFO（last-in-first-out，即类似cache的最频繁使用队列），如果为False，则表示FIFO队列；"><a href="#lifo：borrowObject返回对象时，是采用DEFAULT-LIFO（last-in-first-out，即类似cache的最频繁使用队列），如果为False，则表示FIFO队列；" class="headerlink" title="lifo：borrowObject返回对象时，是采用DEFAULT_LIFO（last in first out，即类似cache的最频繁使用队列），如果为False，则表示FIFO队列；"></a>lifo：borrowObject返回对象时，是采用DEFAULT_LIFO（last in first out，即类似cache的最频繁使用队列），如果为False，则表示FIFO队列；</h1><p>其中JedisPoolConfig对一些参数的默认设置如下：<br>testWhileIdle=true<br>minEvictableIdleTimeMills=60000<br>timeBetweenEvictionRunsMillis=30000<br>numTestsPerEvictionRun=-1</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;blockquote class=&quot;blockquote-center&quot;&gt;逃避未必能躲过，面对未必最难过&lt;/blockquote&gt;&lt;br&gt;在互联网时代的背景下，大数据带来的冲击，是的传统的关系型数据库结构以及数据类型无法应对，比例如大数据时代下的特点是3V(海量Volume，多样Variety，实时Velocity)，3高（高并发，高可用，高性能）。这样的特点也就是的许多菲关系型数据库NoSql（not only sql）的数据库应然而生。&lt;br&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Redis" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
      <category term="分布式缓存" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>Mysql主从数据库的配置</title>
    <link href="http://yoursite.com/2017/09/02/Tomcat%E4%B8%BB%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoursite.com/2017/09/02/Tomcat主从数据库的配置/</id>
    <published>2017-09-01T17:25:17.000Z</published>
    <updated>2017-09-13T04:26:18.000Z</updated>
    
    <content type="html"><![CDATA[<p><blockquote class="blockquote-center">没有实力的发怒，是毫无意义的</blockquote><br>因为实验室的项目需要。我们在自己写项目的时候数据库往往是单个的，是没有容灾备份，没有单点故障的处理，今天我们就说一下我们常用的数据库Mysql的主从备份。<br><a id="more"></a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;blockquote class=&quot;blockquote-center&quot;&gt;没有实力的发怒，是毫无意义的&lt;/blockquote&gt;&lt;br&gt;因为实验室的项目需要。我们在自己写项目的时候数据库往往是单个的，是没有容灾备份，没有单点故障的处理，今天我们就说一下我们常用的数据库Mysql的主从备份。&lt;br&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Mysql" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/"/>
    
    
      <category term="Mysql" scheme="http://yoursite.com/tags/Mysql/"/>
    
      <category term="主从复制" scheme="http://yoursite.com/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>致谢606实验室</title>
    <link href="http://yoursite.com/2017/06/07/%E8%87%B4%E8%B0%A2606%E5%AE%9E%E9%AA%8C%E5%AE%A4/"/>
    <id>http://yoursite.com/2017/06/07/致谢606实验室/</id>
    <published>2017-06-07T05:30:16.000Z</published>
    <updated>2017-06-07T08:34:50.000Z</updated>
    
    <content type="html"><![CDATA[<p><blockquote class="blockquote-center">国事如今谁倚仗，衣带一江而已。</blockquote><br>待续<br><a id="more"></a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;blockquote class=&quot;blockquote-center&quot;&gt;国事如今谁倚仗，衣带一江而已。&lt;/blockquote&gt;&lt;br&gt;待续&lt;br&gt;
    
    </summary>
    
      <category term="随笔" scheme="http://yoursite.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="EGOV" scheme="http://yoursite.com/tags/EGOV/"/>
    
  </entry>
  
  <entry>
    <title>我和Hexo的秘密</title>
    <link href="http://yoursite.com/2017/06/06/%E6%88%91%E5%92%8Chexo%E7%9A%84%E7%A7%98%E5%AF%86/"/>
    <id>http://yoursite.com/2017/06/06/我和hexo的秘密/</id>
    <published>2017-06-06T13:41:44.000Z</published>
    <updated>2017-07-25T15:35:04.000Z</updated>
    
    <content type="html"><![CDATA[<p><blockquote class="blockquote-center">劝君莫惜金缕衣，劝君惜取少年时</blockquote><br><strong>2017年5月29，今天我终于有了自己的博客，开始把其他上面的东西往hexo上搬了，知乎啊，微博啊，CSDN，segmentflaut等上面的东西一点一点的搬过来。</strong><br><a id="more"></a></p>
<h3 id="流量统计"><a href="#流量统计" class="headerlink" title="流量统计"></a>流量统计</h3><p>下面的人数统计和访问统计是用的busuanzi</p>
<h3 id="阅读次数"><a href="#阅读次数" class="headerlink" title="阅读次数"></a>阅读次数</h3><p>文章的阅读次数用的是百度统计和leanCloud</p>
<h3 id="图床"><a href="#图床" class="headerlink" title="图床"></a>图床</h3><p>本站所有的图片都是存储在免费的CDN服务中。Cloudinary提供的图片CDN服务，在Cloudinary中上传图片后，会生成对应的url地址，将地址直接拿来引用即可。</p>
<h3 id="站内搜索"><a href="#站内搜索" class="headerlink" title="站内搜索"></a>站内搜索</h3><p>本站的站内搜索是采用hexo自带的local search</p>
<h3 id="引用站内文章"><a href="#引用站内文章" class="headerlink" title="引用站内文章"></a>引用站内文章</h3><p>可以通过内置标签post_link实现</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;% post_link 文章文件名（不要后缀） 文章标题（可选） %&#125;</div></pre></td></tr></table></figure>
<p>例如 引用hello.md</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;% post_link Hello %&#125;</div></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;% post_link Hello 你好 %&#125;</div></pre></td></tr></table></figure>
<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><p>本地部署，在localhost：4000</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo s</div></pre></td></tr></table></figure>
<p>清除无用的标签，索引，分类</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo clean</div></pre></td></tr></table></figure>
<p>更新部署</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo d -g</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;blockquote class=&quot;blockquote-center&quot;&gt;劝君莫惜金缕衣，劝君惜取少年时&lt;/blockquote&gt;&lt;br&gt;&lt;strong&gt;2017年5月29，今天我终于有了自己的博客，开始把其他上面的东西往hexo上搬了，知乎啊，微博啊，CSDN，segmentflaut等上面的东西一点一点的搬过来。&lt;/strong&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Hexo相关" scheme="http://yoursite.com/categories/Hexo%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
      <category term="博客" scheme="http://yoursite.com/tags/%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>SpringMVC的执行流程</title>
    <link href="http://yoursite.com/2017/06/05/SpringMVC%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/"/>
    <id>http://yoursite.com/2017/06/05/SpringMVC的执行流程/</id>
    <published>2017-06-05T14:06:51.000Z</published>
    <updated>2017-06-06T13:39:52.000Z</updated>
    
    <content type="html"><![CDATA[<p><blockquote class="blockquote-center">三更灯火五更鸡，正是男儿读书时</blockquote><br><strong>在整个Spring MVC 框架中，DispatcherServlet 处于核心位置，负责协调和组织不同组件以完成请求处理并返回响应的工作。</strong><br><a id="more"></a></p>
<h3 id="Spring-MVC-工作流程图"><a href="#Spring-MVC-工作流程图" class="headerlink" title="Spring MVC 工作流程图"></a>Spring MVC 工作流程图</h3><p><img src="http://res.cloudinary.com/drqf361hz/image/upload/v1496755889/SpringMVC%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90_ewz7aa.png" alt=""></p>
<h3 id="SpringMVC-处理请求过程："><a href="#SpringMVC-处理请求过程：" class="headerlink" title="SpringMVC 处理请求过程："></a>SpringMVC 处理请求过程：</h3><ol>
<li>用户向服务器发送请求，请求被Spring 前端控制Servelt DispatcherServlet捕获；</li>
<li>DispatcherServlet对请求URL进行解析，得到请求资源标识符（URI）。然后根据该URI，调用HandlerMapping获得该Handler配置的所有相关的对象（包括Handler对象以及Handler对象对应的拦截器），最后以HandlerExecutionChain对象的形式返回。(DispatcherServlet（中央调度），负责request和response，负责调用处理器映射器查找Handler，负责调用处理器适配器执行Handler，有了前端控制器降低了各个组件之间的耦合性，系统扩展性提高)。</li>
<li>DispatcherServlet 根据获得的Handler，选择一个合适的HandlerAdapter。（附注：如果成功获得HandlerAdapter后，此时将开始执行拦截器的preHandler(…)方法）</li>
<li>提取Request中的模型数据，填充Handler入参，开始执行Handler（Controller)。 在填充Handler的入参过程中，根据你的配置，Spring将帮你做一些额外的工作：<ul>
<li>HttpMessageConveter： 将请求消息（如Json、xml等数据）转换成一个对象，将对象转换为指定的响应信息</li>
<li>数据转换：对请求消息进行数据转换。如String转换成Integer、Double等</li>
<li>数据根式化：对请求消息进行数据格式化。 如将字符串转换成格式化数字或格式化日期等</li>
<li>数据验证： 验证数据的有效性（长度、格式等），验证结果存储到BindingResult或Error中</li>
</ul>
</li>
<li>Handler执行完成后，向DispatcherServlet 返回一个ModelAndView对象；</li>
<li>根据返回的ModelAndView，选择一个适合的ViewResolver（必须是已经注册到Spring容器中的ViewResolver，jsp还是pdf)返回给DispatcherServlet ；</li>
<li>ViewResolver 结合Model和View，来渲染视图</li>
<li>将渲染结果返回给客户端。</li>
</ol>
<h3 id="Spring-MVC工作流程图"><a href="#Spring-MVC工作流程图" class="headerlink" title="Spring MVC工作流程图"></a>Spring MVC工作流程图</h3><p><img src="http://res.cloudinary.com/drqf361hz/image/upload/v1496755888/Spring_MVC%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E5%9B%BE_lhxuct.png" alt=""></p>
<h3 id="UML时序图"><a href="#UML时序图" class="headerlink" title="UML时序图"></a>UML时序图</h3><p><img src="http://res.cloudinary.com/drqf361hz/image/upload/v1496755881/Spring_MVC-UML_sdj0tz.png" alt=""></p>
<h4 id="组件说明"><a href="#组件说明" class="headerlink" title="组件说明:"></a>组件说明:</h4><p>以下组件通常使用框架提供实现：</p>
<ul>
<li>DispatcherServlet：作为前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。</li>
<li>HandlerMapping：通过扩展处理器映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。</li>
<li>HandlAdapter：通过扩展处理器适配器，支持更多类型的处理器。</li>
<li>ViewResolver：通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;blockquote class=&quot;blockquote-center&quot;&gt;三更灯火五更鸡，正是男儿读书时&lt;/blockquote&gt;&lt;br&gt;&lt;strong&gt;在整个Spring MVC 框架中，DispatcherServlet 处于核心位置，负责协调和组织不同组件以完成请求处理并返回响应的工作。&lt;/strong&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Web开发框架" scheme="http://yoursite.com/categories/Web%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/"/>
    
      <category term="Spring" scheme="http://yoursite.com/categories/Web%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/Spring/"/>
    
    
      <category term="SpringMVC" scheme="http://yoursite.com/tags/SpringMVC/"/>
    
      <category term="SpringMVC执行流程" scheme="http://yoursite.com/tags/SpringMVC%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Spark On YARN集群环境搭建</title>
    <link href="http://yoursite.com/2017/06/02/Spark-On-YARN%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>http://yoursite.com/2017/06/02/Spark-On-YARN集群环境搭建/</id>
    <published>2017-06-02T14:54:56.000Z</published>
    <updated>2017-07-19T12:30:38.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center">尽人事，听天命</blockquote>

<p>最近因为写论文的实验需要用到Spark集群，所以就需要自己动手配置一下，尽管现在有很多的云平台提供了很好的云服务，可以很方面的使用，但是收费还是很高的。自己亲自配置一下，才知道其实并不是很难，废话不多说，下面进入正题。<br><a id="more"></a></p>
<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>用户尽量使用带有root权限的用户，这里假设每个机器的用户是spark，可以减少不必要的麻烦。如何创建root权限用户，这里就不说了，每个节点上的用户都是一样的，安装的路径也必须是一致的。</p>
<h1 id="软件准备："><a href="#软件准备：" class="headerlink" title="软件准备："></a>软件准备：</h1><ul>
<li>Jdk</li>
<li>Scala</li>
<li>Hadoop</li>
<li>Spark</li>
</ul>
<p>这里的版本，大家可以选择最新的版本就行。jdk 和 scala 的安装和配置大同小异，</p>
<h1 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h1><p>我们的目标是用主机名来代替主机IP，假设我们现在的机器有三台，我们选择其中一台作为master节点，其他两台作为worker节点，他们的IP为：</p>
<blockquote>
<p>10.1.130.21<br>10.1.130.22<br>10.1.130.23</p>
</blockquote>
<p>这里，我们想把21作为主节点，22，23作为工作节点。首先是要把每个机器的主机名（hostname）改一下，方法是 <code>vi /etc/hostname</code></p>
<p>21节点：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">10.1.130.21  master</div></pre></td></tr></table></figure>
<p>22节点：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">10.1.130.22  salve1</div></pre></td></tr></table></figure>
<p>23节点：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">10.1.130.23  slave2</div></pre></td></tr></table></figure>
<p>配置完主机名之后，需要重启生效。</p>
<p>然后就是修改每个节点的hosts文件，方法是<code>vi /etc/hosts</code></p>
<p>每个节点都做同样的修改，添加如下配置：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">10.1.130.21  master</div><div class="line">10.1.130.22  salve1</div><div class="line">10.1.130.23  slave2</div></pre></td></tr></table></figure>
<p>配置完成后，需要互ping一下，检查是否成功，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">spark@master$ ping slave1 <span class="comment">#从master ping slave1，其他的类似</span></div></pre></td></tr></table></figure>
<h1 id="SSH免密登录"><a href="#SSH免密登录" class="headerlink" title="SSH免密登录"></a>SSH免密登录</h1><p>如果机器没有安装ssh服务可以安装一下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install openssh-server</div></pre></td></tr></table></figure>
<p>免密登录，可以参考之间的方法 <a href="/2017/05/31/SSH免密登录/" title="SSH免密登录">SSH免密登录</a></p>
<h1 id="Java和Scala的安装"><a href="#Java和Scala的安装" class="headerlink" title="Java和Scala的安装"></a>Java和Scala的安装</h1><p><strong>以下所有的安装都是在master节点上进行的。</strong></p>
<p>从官网下载最新版<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="external">Java</a>和<a href="https://www.scala-lang.org/" target="_blank" rel="external">Scala</a>就可以，它们的安装方式差不多，</p>
<h2 id="Java的安装"><a href="#Java的安装" class="headerlink" title="Java的安装"></a>Java的安装</h2><p>在你想要的安装的目录下解压,这里我们在自己用户下新建一个文件夹叫做app，注意不要用<code>sudo</code>来建立,直接在每一个节点下<code>mkdir app</code>就行了，将源文件放在app中，然后解压。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> app</div><div class="line">tar -zxvf jdk-7u75-linux-x64.gz</div></pre></td></tr></table></figure>
<p>修改环境变量<code>vi .bashrc</code>, 添加下列内容,注意这里spark是你的用户名，即在你的户用文件夹下。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> WORK_SPACE=/home/spark/app/</div><div class="line"><span class="built_in">export</span> JAVA_HOME=<span class="variable">$WORK_SPACE</span>/jdk1.7.0_75</div><div class="line"><span class="built_in">export</span> JRE_HOME=/home/spark/work/jdk1.7.0_75/jre</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$JAVA_HOME</span>/jre/bin:<span class="variable">$PATH</span></div><div class="line"><span class="built_in">export</span> CLASSPATH=<span class="variable">$CLASSPATH</span>:.:<span class="variable">$JAVA_HOME</span>/lib:<span class="variable">$JAVA_HOME</span>/jre/lib</div></pre></td></tr></table></figure>
<p>生效环境变量</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">source</span> .bashrc</div></pre></td></tr></table></figure>
<p>查看java版本，如果打印出如下版本信息，则说明安装成功</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ java -version </div><div class="line">java version <span class="string">"1.7.0_75"</span></div><div class="line">Java(TM) SE Runtime Environment (build 1.7.0_75-b13)</div><div class="line">Java HotSpot(TM) 64-Bit Server VM (build 24.75-b04, mixed mode)</div></pre></td></tr></table></figure>
<h2 id="Scala的安装"><a href="#Scala的安装" class="headerlink" title="Scala的安装"></a>Scala的安装</h2><p>Scala 的安装也是一样的，同样解压在app文件夹下，配置环境变量：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> SCALA_HOME=<span class="variable">$WORK_SPACE</span>/scala-2.10.4</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SCALA_HOME</span>/bin</div></pre></td></tr></table></figure>
<p>生效环境变量</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">source</span> .bashrc</div></pre></td></tr></table></figure>
<p>查看Scala版本，如果打印出如下版本信息，则说明安装成功</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ scala -version       </div><div class="line">Scala code runner version 2.10.4 -- Copyright 2002-2013, LAMP/EPFL</div></pre></td></tr></table></figure>
<p>至此，我们的Java和Scala的安装工作就结束了，我们需要将安装的目录分发到slave1和slave2中，同时slave1和slave2的环境变量也需要像master中一样配置.<br>分发</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">scp -r ~/app/jdk1.7.0_75 spark@slave1:~/app/</div><div class="line">scp -r ~/app/jdk1.7.0_75 spark@slave2:~/app/</div><div class="line">scp -r ~/app/scala-2.10.4 spark@slave1:~/app/</div><div class="line">scp -r ~/app/scala-2.10.4 spark@slave1:~/app/</div></pre></td></tr></table></figure>
<p>修改slave1和slave2环境的环境变量，可以直接复制。然后在slave1和slave2中分别测试一下有没有安装成功。</p>
<h1 id="安装配置-Hadoop-YARN"><a href="#安装配置-Hadoop-YARN" class="headerlink" title="安装配置 Hadoop YARN"></a>安装配置 Hadoop YARN</h1><h2 id="下载解压"><a href="#下载解压" class="headerlink" title="下载解压"></a>下载解压</h2><p>从<a href="http://hadoop.apache.org/#Download+Hadoop" target="_blank" rel="external">官网</a>下载hadoop,这里我们以 hadoop2.6.0 版本为例。</p>
<p>同样我们在~/app中解压</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tar -zxvf hadoop-2.6.0.tar.gz</div></pre></td></tr></table></figure>
<h2 id="配置Hadoop"><a href="#配置Hadoop" class="headerlink" title="配置Hadoop"></a>配置Hadoop</h2><p>同样我们可以在 <code>.bashrc</code>中配置Hadoop的环境变量</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> HADOOP_HOME=/home/spark/app/hadoop-2.6.0</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin</div></pre></td></tr></table></figure>
<p>需要配置的配置文件都在hadoop根目录下的<code>etc/hadoop</code>中，一共需要配置7个文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">hadoop-env.sh</div><div class="line">yarn-env.sh</div><div class="line">slaves</div><div class="line">core-site.xml</div><div class="line">hdfs-site.xml</div><div class="line">maprd-site.xml</div><div class="line">yarn-site.xml</div></pre></td></tr></table></figure>
<ol>
<li><p>在<code>hadoop-env.sh</code>中配置JAVA_HOME</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export JAVA_HOME=/home/spark/app/jdk1.7.0_75</div></pre></td></tr></table></figure>
</li>
<li><p>在<code>yarn-env.sh</code>中配置JAVA_HOME</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> JAVA_HOME=/home/spark/app/jdk1.7.0_75</div></pre></td></tr></table></figure>
</li>
<li><p>在slaves中配置slave节点的ip或者host，</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">slave1</div><div class="line">slave2</div></pre></td></tr></table></figure>
</li>
<li><p>修改core-site.xml</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">        &lt;value&gt;hdfs://master:9000/&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">         &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">         &lt;value&gt;file:/home/spark/workspace/hadoop-2.6.0/tmp&lt;/value&gt;</div><div class="line">         &lt;description&gt;Abase <span class="keyword">for</span> other temporary directories.&lt;/description&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>修改hdfs-site.xml</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</div><div class="line">        &lt;value&gt;master:9001&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</div><div class="line">        &lt;value&gt;file:/home/spark/app/hadoop-2.6.0/dfs/name&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</div><div class="line">        &lt;value&gt;file:/home/spark/app/hadoop-2.6.0/dfs/data&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</div><div class="line">        &lt;value&gt;3&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">    	&lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt;</div><div class="line">    	&lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>修改mapred-site.xml</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</div><div class="line">        &lt;value&gt;yarn&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>修改yarn-site.xml</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;</div><div class="line">        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">    	&lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;</div><div class="line">    	&lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">    	&lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</div><div class="line">    	&lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">    	&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</div><div class="line">    	&lt;value&gt;amdnode0&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;master:8032&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;master:8030&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;master:8035&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;master:8033&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;master:8088&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
</ol>
<p>这是我自己的配置，大家可以根据自己的需要修改，将配置好的hadoop-2.6.0文件夹分发给所有slaves吧。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scp -r ~/app/hadoop-2.6.0 spark@slave1:~/app/</div><div class="line">scp -r ~/app/hadoop-2.6.0 spark@slave2:~/app/</div></pre></td></tr></table></figure>
<h2 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h2><p>在 master 上执行以下操作，就可以启动 hadoop 了,因为我们配置了Hadoop的环境变量所以就可以在任意目录下启动Hadoop了。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">start-dfs.sh               <span class="comment">#启动dfs,如果没有配置的话就是sbin/start-dfs.sh                </span></div><div class="line">start-yarn.sh              <span class="comment">#启动yarn,如果没有配置的话就是sbin/start-yarn.sh</span></div></pre></td></tr></table></figure>
<h2 id="验证-Hadoop-是否安装成功"><a href="#验证-Hadoop-是否安装成功" class="headerlink" title="验证 Hadoop 是否安装成功"></a>验证 Hadoop 是否安装成功</h2><p>可以通过jps命令查看各个节点启动的进程是否正常。在 master 上应该有以下几个进程：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ jps  <span class="comment">#run on master</span></div><div class="line">3407 SecondaryNameNode</div><div class="line">3218 NameNode</div><div class="line">3552 ResourceManager</div><div class="line">3910 Jps</div></pre></td></tr></table></figure>
<p>在每个slave上应该有以下几个进程：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ jps   <span class="comment">#run on slaves</span></div><div class="line">2072 NodeManager</div><div class="line">2213 Jps</div><div class="line">1962 DataNode</div></pre></td></tr></table></figure>
<p>或者在浏览器中输入 <a href="http://master:8088" target="_blank" rel="external">http://master:8088</a> ，应该有 hadoop 的管理界面出来了，并能看到 slave1 和 slave2 节点。也可以通过 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop dfsadmin -report</div></pre></td></tr></table></figure>
<p>查看节点使用情况。</p>
<h1 id="Spark安装"><a href="#Spark安装" class="headerlink" title="Spark安装"></a>Spark安装</h1><h2 id="下载解压-1"><a href="#下载解压-1" class="headerlink" title="下载解压"></a>下载解压</h2><p>进入官方下载地址下载最新版<a href="https://spark.apache.org/" target="_blank" rel="external">Spark</a>。我下载的是 spark-1.3.0-bin-hadoop2.4.tgz。</p>
<p>在~/app目录下解压</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -zxvf spark-1.3.0-bin-hadoop2.4.tgz</div><div class="line">mv spark-1.3.0-bin-hadoop2.4 spark-1.3.0    <span class="comment">#如果觉得原来的文件名太长了，可以修改下</span></div></pre></td></tr></table></figure>
<h2 id="配置-Spark"><a href="#配置-Spark" class="headerlink" title="配置 Spark"></a>配置 Spark</h2><p>spark的配置文件在spark根目录下的<code>conf</code>中, Spark需要修改的配置文件只有两个：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">spark-env.sh </div><div class="line">slaves</div></pre></td></tr></table></figure>
<ol>
<li><p>在conf目录下将<code>spark-env.sh.template</code>复制成<code>spark-env.sh</code></p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> ~/app/spark-1.3.0/conf    <span class="comment">#进入spark配置目录</span></div><div class="line">cp spark-env.sh.template spark-env.sh   <span class="comment">#从配置模板复制</span></div><div class="line">vi spark-env.sh     <span class="comment">#添加配置内容</span></div></pre></td></tr></table></figure>
<p> 在spark-env.sh末尾添加以下内容（这是我的配置，你可以自行修改）：</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> SCALA_HOME=/home/spark/app/scala-2.10.4</div><div class="line"><span class="built_in">export</span> JAVA_HOME=/home/spark/app/jdk1.7.0_75</div><div class="line"><span class="built_in">export</span> HADOOP_HOME=/home/spark/app/hadoop-2.6.0</div><div class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$HADOOP_HOME</span>/etc/hadoop</div><div class="line">SPARK_MASTER_IP=master</div><div class="line">SPARK_LOCAL_DIRS=/home/spark/app/spark-1.3.0</div><div class="line">SPARK_DRIVER_MEMORY=1G</div></pre></td></tr></table></figure>
<p> 注：在设置Worker进程的CPU个数和内存大小，要注意机器的实际硬件条件，如果配置的超过当前Worker节点的硬件条件，Worker进程会启动失败。</p>
</li>
<li><p>修改slaves文件下slaves的主机名：</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">slave1</div><div class="line">slave2</div></pre></td></tr></table></figure>
</li>
</ol>
<p>将配置好的spark-1.3.0文件夹分发给所有slaves吧</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scp -r ~/app/spark-1.3.0 spark@slave1:~/workspace/</div><div class="line">scp -r ~/app/spark-1.3.0 spark@slave2:~/workspace/</div></pre></td></tr></table></figure>
<h2 id="启动Spark"><a href="#启动Spark" class="headerlink" title="启动Spark"></a>启动Spark</h2><p>在spark的根目录下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sbin/start-all.sh</div></pre></td></tr></table></figure>
<p>验证 Spark 是否安装成功<br>用jps检查，在 master 上应该有以下几个进程：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$ jps</div><div class="line">7949 Jps</div><div class="line">7328 SecondaryNameNode</div><div class="line">7805 Master</div><div class="line">7137 NameNode</div><div class="line">7475 ResourceManager</div></pre></td></tr></table></figure>
<p>在 slave 上应该有以下几个进程：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$jps</span></div><div class="line">3132 DataNode</div><div class="line">3759 Worker</div><div class="line">3858 Jps</div><div class="line">3231 NodeManager</div></pre></td></tr></table></figure>
<p>也可以进入Spark的Web管理页面： <a href="http://master:8080" target="_blank" rel="external">http://master:8080</a></p>
<p><strong>注意：三个节点的防火墙要关掉，不然很容易出错，这里中间很多的细节都没有涉及到，只是个大概的流程，我相信，每个人刚学的时候都不会一次性的成功，但是者未必不是好事，有些坑是需要踩过才知道，这里有很多的坑，祝大家早日脱坑。</strong></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;尽人事，听天命&lt;/blockquote&gt;

&lt;p&gt;最近因为写论文的实验需要用到Spark集群，所以就需要自己动手配置一下，尽管现在有很多的云平台提供了很好的云服务，可以很方面的使用，但是收费还是很高的。自己亲自配置一下，才知道其实并不是很难，废话不多说，下面进入正题。&lt;br&gt;
    
    </summary>
    
      <category term="分布式系统" scheme="http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
      <category term="YARN" scheme="http://yoursite.com/tags/YARN/"/>
    
      <category term="分布式环境搭建" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>SSH免密登录</title>
    <link href="http://yoursite.com/2017/05/31/SSH%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/"/>
    <id>http://yoursite.com/2017/05/31/SSH免密登录/</id>
    <published>2017-05-31T05:56:07.000Z</published>
    <updated>2017-06-03T03:40:42.000Z</updated>
    
    <content type="html"><![CDATA[<p><blockquote class="blockquote-center">纸上得来终觉浅，要知此事须躬行</blockquote><br>在配置集群的时候，ssh免密登录时第一步。<strong>其实linux免密登录很简单，四步就可以解决问题</strong><br><a id="more"></a></p>
<h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><p>假设有两台机器他们的IP和主机名是：<br><em>M1-IP</em>：<code>10.1.130.2</code>         <em>主机名</em>：<code>m1</code><br><em>M2-IP</em>：<code>10.1.130.3</code>         <em>主机名</em>：<code>m2</code><br>如果想要更改主机名，可以在每台机器的<code>/etc/hostname</code>中更改，但是需要<strong>重启生效</strong>。</p>
<h3 id="映射主机名"><a href="#映射主机名" class="headerlink" title="映射主机名"></a>映射主机名</h3><p>每个机器都进入 <code>/etc/hosts</code> ，并添加所有的主机名和IP映射<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">10.1.130.2   m1</div><div class="line">10.1.130.3   m2</div></pre></td></tr></table></figure></p>
<h3 id="生成公钥"><a href="#生成公钥" class="headerlink" title="生成公钥"></a>生成公钥</h3><p>执行以下命令，生成公钥，一直回车就行，如果之前有的就输入y就覆盖就行。默认目录是放在 <code>~/.ssh</code> 下面，名为<code>id_rsa.pub</code>。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ssh-keygen -t rsa</div></pre></td></tr></table></figure></p>
<h3 id="汇总公钥"><a href="#汇总公钥" class="headerlink" title="汇总公钥"></a>汇总公钥</h3><ul>
<li><p>汇总公钥至同一机器（为了方面下一步），假如在<code>m2</code>中将公钥复制到<code>m1</code>。</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scp id_rsa.pub m1@10.1.1130.2:~/.ssh/id_rsa.pub.m2</div></pre></td></tr></table></figure>
</li>
<li><p>将公钥合并至 <code>authorized_keys</code></p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat id_rsa.pub* &gt;&gt;authorized_keys</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="分发公钥"><a href="#分发公钥" class="headerlink" title="分发公钥"></a>分发公钥</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scp authorized_keys m2@10.1.1130.3:~/.ssh</div></pre></td></tr></table></figure>
<p>大工告成</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;blockquote class=&quot;blockquote-center&quot;&gt;纸上得来终觉浅，要知此事须躬行&lt;/blockquote&gt;&lt;br&gt;在配置集群的时候，ssh免密登录时第一步。&lt;strong&gt;其实linux免密登录很简单，四步就可以解决问题&lt;/strong&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
      <category term="免密登录" scheme="http://yoursite.com/tags/%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>HDFS常用命令</title>
    <link href="http://yoursite.com/2017/05/31/HDFS%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2017/05/31/HDFS常用命令/</id>
    <published>2017-05-31T02:40:58.000Z</published>
    <updated>2017-06-19T12:31:29.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center">衣带渐宽终不悔，为伊消得人憔悴</blockquote>

<h2 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h2><ul>
<li>建立目录<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop dfs -mkdir -p /user/hadoop/examples   <span class="comment">#加上-p是所有目录都要建立</span></div><div class="line">eadoop dfs -mkdir  /user/hadoop/examples1    <span class="comment">#建立examples1目录</span></div></pre></td></tr></table></figure>
</li>
</ul>
<a id="more"></a> 
<ul>
<li>删除目录<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop dfs -rm -r /user/hadoop/examples    #加上-r，删除examples</div><div class="line">hadoop dfs -rm -r /user                    #删除user目录</div></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>列出HDFS下的文件(夹)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop dfs -ls /                 #查看hdfs根目录下的文件夹(文件)</div><div class="line">hadoop dfs -ls /user/data        #查看某个目录下的文件夹(文件)</div></pre></td></tr></table></figure>
</li>
<li><p>查看文件内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop dfs -cat /user/data/in/word.txt     #查看文件内容，必须是一个文件，不能时目录</div></pre></td></tr></table></figure>
</li>
<li><p>将hdfs上的文件(夹)复制到本地的文件系统</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">hadoop dfs -get /user/data   rename                                                      #将data目录复制到当前执行该命令的本地文件系统，并重命名为rename</div><div class="line">hadoop dfs -get /user/data  /home/user/data  rename                                     #将data目录复制到本地指定目录下，并重命名为rename</div><div class="line"></div><div class="line">hadoop dfs -get /user/data  /home/user/data/core-site.xml  /home/user/data/rename.xml    #将core-site.xml复制到本地指定目录下，并重命名为rename.xml</div><div class="line"></div><div class="line">hadoop dfs -getmerger /user/data/in merge.xml                                            #将hdfs中某个目录下的的文件合并并下载到本地当前目录</div></pre></td></tr></table></figure>
</li>
<li><p>将本地文件系统上传到hdfs上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop dfs -put file /user/data</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="管理与更新"><a href="#管理与更新" class="headerlink" title="管理与更新"></a>管理与更新</h2><ul>
<li><p>执行基本信息, 查看HDFS的基本统计信息:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop dfsadmin -report</div></pre></td></tr></table></figure>
</li>
<li><p>HDFS的数据在各个DataNode中的分布可能很不均匀，尤其是在DataNode节点出现故障或新增DataNode节点时。新增数据块时NameNode对DataNode节点的选择策略也有可能导致数据块分布不均匀。用户可以使用命令重新平衡DataNode上的数据块的分布:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop$bin/start-balancer.sh</div></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;衣带渐宽终不悔，为伊消得人憔悴&lt;/blockquote&gt;

&lt;h2 id=&quot;文件操作&quot;&gt;&lt;a href=&quot;#文件操作&quot; class=&quot;headerlink&quot; title=&quot;文件操作&quot;&gt;&lt;/a&gt;文件操作&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;建立目录&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;hadoop dfs -mkdir -p /user/hadoop/examples   &lt;span class=&quot;comment&quot;&gt;#加上-p是所有目录都要建立&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;eadoop dfs -mkdir  /user/hadoop/examples1    &lt;span class=&quot;comment&quot;&gt;#建立examples1目录&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="分布式系统" scheme="http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Git常用命令</title>
    <link href="http://yoursite.com/2017/05/31/Git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2017/05/31/Git常用命令/</id>
    <published>2017-05-31T02:15:15.000Z</published>
    <updated>2017-06-03T03:39:05.000Z</updated>
    
    <content type="html"><![CDATA[<p><blockquote class="blockquote-center">优秀的人，不是不合群，而是他们合群的人里面没有你</blockquote></p>
<h2 id="获取仓库"><a href="#获取仓库" class="headerlink" title="获取仓库"></a>获取仓库</h2><ul>
<li>初始化一个版本仓库<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git init</div></pre></td></tr></table></figure>
</li>
</ul>
<a id="more"></a>
<ul>
<li><p>Clone远程版本库</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> git@xbc.me:wordpress.git</div></pre></td></tr></table></figure>
</li>
<li><p>添加远程版本库origin，语法为 git remote add [shortname] [url]</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git remote add origin git@xbc.me:wordpress.git</div></pre></td></tr></table></figure>
</li>
<li><p>查看远程仓库</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git remote -v</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="提交修改"><a href="#提交修改" class="headerlink" title="提交修改"></a>提交修改</h2><ul>
<li><p>添加当前修改的文件到暂存区</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git add .</div></pre></td></tr></table></figure>
</li>
<li><p>如果你自动追踪文件，包括你已经手动删除的，状态为Deleted的文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git add -u</div></pre></td></tr></table></figure>
</li>
<li><p>提交你的修改</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git commit –m <span class="string">"你的注释"</span></div></pre></td></tr></table></figure>
</li>
<li><p>推送你的更新到远程服务器,语法为 git push [远程名] [本地分支]:[远程分支]</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git push origin master</div></pre></td></tr></table></figure>
</li>
<li><p>查看文件状态</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git status</div></pre></td></tr></table></figure>
</li>
<li><p>跟踪新文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git add readme.txt</div></pre></td></tr></table></figure>
</li>
<li><p>从当前跟踪列表移除文件，并完全删除</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git rm readme.txt</div></pre></td></tr></table></figure>
</li>
<li><p>仅在暂存区删除，保留文件在当前目录，不再跟踪</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git rm –cached readme.txt</div></pre></td></tr></table></figure>
</li>
<li><p>重命名文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git mv reademe.txt readme</div></pre></td></tr></table></figure>
</li>
<li><p>查看提交的历史记录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">log</span></div></pre></td></tr></table></figure>
</li>
<li><p>修改最后一次提交注释的，利用–amend参数</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git commit --amend</div></pre></td></tr></table></figure>
</li>
<li><p>忘记提交某些修改，下面的三条命令只会得到一个提交</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git commit –m <span class="string">"add readme.txt"</span></div><div class="line">git add readme_forgotten</div><div class="line">git commit –amend</div></pre></td></tr></table></figure>
</li>
<li><p>假设你已经使用<code>git add .</code>，将修改过的文件a、b加到暂存区<br>现在你只想提交a文件，不想提交b文件，应该这样</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git reset HEAD b</div></pre></td></tr></table></figure>
</li>
<li><p>取消对文件的修改</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git checkout –- readme.txt</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="分支管理"><a href="#分支管理" class="headerlink" title="分支管理"></a>分支管理</h2><ul>
<li><p>创建一个分支</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git branch iss53</div></pre></td></tr></table></figure>
</li>
<li><p>切换工作目录到iss53</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git chekcout iss53</div></pre></td></tr></table></figure>
</li>
<li><p>将上面的命令合在一起，创建iss53分支并切换到iss53</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git chekcout –b iss53</div></pre></td></tr></table></figure>
</li>
<li><p>合并iss53分支，当前工作目录为master</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git merge iss53</div></pre></td></tr></table></figure>
</li>
<li><p>合并完成后，没有出现冲突，删除iss53分支</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git branch –d iss53</div></pre></td></tr></table></figure>
</li>
<li><p>拉去远程仓库的数据，语法为 git fetch [remote-name]</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git fetch</div></pre></td></tr></table></figure>
</li>
<li><p>fetch 会拉去最新的远程仓库数据，但不会自动到当前目录下，要自动合并</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git pull</div></pre></td></tr></table></figure>
</li>
<li><p>查看远程仓库的信息</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git remote show origin</div></pre></td></tr></table></figure>
</li>
<li><p>建立本地的dev分支追踪远程仓库的develop分支</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git checkout –b dev origin/develop+ <span class="comment">#分支管理</span></div></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;blockquote class=&quot;blockquote-center&quot;&gt;优秀的人，不是不合群，而是他们合群的人里面没有你&lt;/blockquote&gt;&lt;/p&gt;
&lt;h2 id=&quot;获取仓库&quot;&gt;&lt;a href=&quot;#获取仓库&quot; class=&quot;headerlink&quot; title=&quot;获取仓库&quot;&gt;&lt;/a&gt;获取仓库&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;初始化一个版本仓库&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;git init&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Git" scheme="http://yoursite.com/categories/Git/"/>
    
    
      <category term="git" scheme="http://yoursite.com/tags/git/"/>
    
  </entry>
  
</feed>
